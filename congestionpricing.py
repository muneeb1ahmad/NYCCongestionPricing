# -*- coding: utf-8 -*-
"""CongestionPricing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nN20Xpne1HUSAUw_AZDbvsO4jLM5Fv23
"""

!pip install opencv-python opencv-python-headless

!wget https://pjreddie.com/media/files/yolov3.weights
!wget https://github.com/pjreddie/darknet/blob/master/cfg/yolov3.cfg
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names

# Re-download YOLOv3 .cfg file from the official source
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg

# List files to ensure yolov3.cfg is downloaded correctly
!ls -lh

import cv2
import numpy as np

# Download YOLOv3 weights and config files
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg
!wget https://pjreddie.com/media/files/yolov3.weights

# Load YOLO
yolo_net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")

# Get YOLO layer names
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in yolo_net.getLayers()]

# Load class labels (COCO dataset labels)
with open("coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to perform detection
def detect_vehicles(image):
    height, width, channels = image.shape

    # Prepare the image for YOLO
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outputs = yolo_net.forward(output_layers)

    # Process detections
    vehicles = []
    for out in outputs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            # Detect only vehicles (cars, trucks, buses)
            if confidence > 0.5 and class_id in [2, 5, 7]:  # 2=car, 5=bus, 7=truck in COCO
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                # Draw bounding box around the vehicle
                cv2.rectangle(image, (center_x - w // 2, center_y - h // 2),
                              (center_x + w // 2, center_y + h // 2), (0, 255, 0), 2)

                vehicles.append((class_id, confidence, (center_x, center_y, w, h)))

    return image, vehicles


# Example usage:
# Fetch an image (for example, from webcam or uploaded)
img = cv2.imread("image.jpg")  # Load an example image
output_img, detected_vehicles = detect_vehicles(img)

# Show result (in Colab, you can use IPython display for images)
from google.colab.patches import cv2_imshow
cv2_imshow(output_img)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Rename the downloaded files to match the expected names
!mv yolov3.cfg.2 yolov3.cfg
!mv yolov3.weights.1 yolov3.weights

!ls -lh

import cv2
import numpy as np

# Load YOLO model
yolo_net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")

# Get YOLO layer names
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i[0] - 1] for i in yolo_net.getLayers()]

# Load class labels (COCO dataset labels)
with open("coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to perform detection
def detect_vehicles(image):
    height, width, channels = image.shape

    # Prepare the image for YOLO
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outputs = yolo_net.forward(output_layers)

    # Process detections
    vehicles = []
    for out in outputs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            # Detect only vehicles (cars, trucks, buses)
            if confidence > 0.5 and class_id in [2, 5, 7]:  # 2=car, 5=bus, 7=truck in COCO
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                # Draw bounding box around the vehicle
                cv2.rectangle(image, (center_x - w // 2, center_y - h // 2),
                              (center_x + w // 2, center_y + h // 2), (0, 255, 0), 2)

                vehicles.append((class_id, confidence, (center_x, center_y, w, h)))

    return image, vehicles


# Example usage:
# Load an image from file (make sure the image file exists)
img = cv2.imread("image.jpg")  # Replace with your image file path
output_img, detected_vehicles = detect_vehicles(img)

# Show result (in Colab, you can use IPython display for images)
from google.colab.patches import cv2_imshow
cv2_imshow(output_img)
cv2.waitKey(0)
cv2.destroyAllWindows()

import cv2
import numpy as np

# Load YOLO model
yolo_net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")

# Get YOLO layer names and output layers
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]

# Load class labels (COCO dataset labels)
with open("coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to perform detection
def detect_vehicles(image):
    height, width, channels = image.shape

    # Prepare the image for YOLO
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outputs = yolo_net.forward(output_layers)

    # Process detections
    vehicles = []
    for out in outputs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            # Detect only vehicles (cars, trucks, buses)
            if confidence > 0.5 and class_id in [2, 5, 7]:  # 2=car, 5=bus, 7=truck in COCO
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)

                # Draw bounding box around the vehicle
                cv2.rectangle(image, (center_x - w // 2, center_y - h // 2),
                              (center_x + w // 2, center_y + h // 2), (0, 255, 0), 2)

                vehicles.append((class_id, confidence, (center_x, center_y, w, h)))

    return image, vehicles


# Example usage:
# Load an image from file (make sure the image file exists)
img = cv2.imread("image.jpg")  # Replace with your image file path
output_img, detected_vehicles = detect_vehicles(img)

# Show result (in Colab, you can use IPython display for images)
from google.colab.patches import cv2_imshow
cv2_imshow(output_img)
cv2.waitKey(0)
cv2.destroyAllWindows()

import requests
import cv2
import numpy as np
import time
from google.colab.patches import cv2_imshow

# Load YOLO
yolo_net = cv2.dnn.readNet("yolov3.weights", "yolov3.cfg")
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]

# Load class labels (COCO dataset labels)
with open("coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Initialize MultiTracker (for tracking multiple objects)
tracker = cv2.legacy.MultiTracker_create()

# API URL for fetching images from NYC webcam
base_url = "https://webcams.nyctmc.org/api/cameras"

# Function to fetch webcam image
def fetch_image_from_webcam(camera_id):
    url = f"https://webcams.nyctmc.org/api/cameras/b5a78bda-3ca9-4ad4-bd03-4cee70baba2d/image"
    response = requests.get(url)
    if response.status_code == 200:
        return np.array(bytearray(response.content), dtype=np.uint8)
    else:
        print("Failed to fetch image.")
        return None

# Detect vehicles in the image
def detect_vehicles(image):
    height, width, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outputs = yolo_net.forward(output_layers)

    vehicles = []  # List to store vehicle information
    for out in outputs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5:  # Adjust confidence threshold
                if class_id == 2:  # Only track cars (class_id == 2 for car in COCO dataset)
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)

                    # Create a bounding box for the car
                    box = (center_x - w // 2, center_y - h // 2, w, h)

                    # Add tracker for the detected car (initialize tracker only once)
                    tracker.add(cv2.legacy.TrackerCSRT_create(), image, box)

                    vehicles.append((class_id, confidence, (center_x, center_y, w, h)))

    return image, vehicles

# Function to continuously fetch, detect, and track cars
def display_and_track_cars(camera_id):
    while True:
        # Fetch image from webcam
        image_data = fetch_image_from_webcam(camera_id)
        if image_data is None:
            break

        # Convert the fetched image data to an OpenCV image
        image = cv2.imdecode(image_data, cv2.IMREAD_COLOR)

        # Detect vehicles (initialize trackers for new detections)
        image, detected_vehicles = detect_vehicles(image)

        # Update tracker and get the new bounding boxes for each tracked vehicle
        success, boxes = tracker.update(image)

        # Draw only bounding boxes for detected and tracked vehicles (no labels)
        for i, box in enumerate(boxes):
            x, y, w, h = [int(v) for v in box]
            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green boxes

        # Display the image with tracked vehicles using Google Colab's cv2_imshow
        cv2_imshow(image)

        # Wait for 1 second before fetching the next image
        time.sleep(1)

# Replace with the actual camera ID from the NYC webcam API
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Example camera ID
display_and_track_cars(camera_id)

import requests
import cv2
import numpy as np
import time
from google.colab.patches import cv2_imshow

# Load Haar Cascade for Car Detection
car_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_car.xml')

# API URL for fetching images from NYC webcam
base_url = "https://webcams.nyctmc.org/api/cameras"

# Variable to keep track of total congestion price
total_congestion_price = 0

# Function to fetch webcam image
def fetch_image_from_webcam(camera_id):
    url = f"https://webcams.nyctmc.org/api/cameras/b5a78bda-3ca9-4ad4-bd03-4cee70baba2d/image"
    response = requests.get(url)
    if response.status_code == 200:
        return np.array(bytearray(response.content), dtype=np.uint8)
    else:
        print("Failed to fetch image.")
        return None

# Detect vehicles using Haar Cascade
def detect_vehicles_haar(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Detect cars
    cars = car_cascade.detectMultiScale(gray, 1.1, 1)

    vehicles = []
    for (x, y, w, h) in cars:
        # Add vehicle to the list
        vehicles.append((x, y, w, h))

        # Draw rectangle around the car
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green box

    return image, vehicles

# Function to continuously fetch, detect, and track cars with congestion price
def display_and_track_cars(camera_id):
    global total_congestion_price  # To update the global price

    while True:
        # Fetch image from webcam
        image_data = fetch_image_from_webcam(camera_id)
        if image_data is None:
            break

        # Convert the fetched image data to an OpenCV image
        image = cv2.imdecode(image_data, cv2.IMREAD_COLOR)

        # Detect vehicles using Haar Cascade
        image, detected_vehicles = detect_vehicles_haar(image)

        # For each detected car, add $9 to the congestion price
        if detected_vehicles:
            total_congestion_price += 9 * len(detected_vehicles)  # Add $9 per vehicle detected

        # Display the total congestion price on the image
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(image, f"Total Congestion Price: ${total_congestion_price}",
                    (10, 30), font, 1, (255, 255, 255), 2, cv2.LINE_AA)

        # Display the image with tracked vehicles using Google Colab's cv2_imshow
        cv2_imshow(image)

        # Wait for 1 second before fetching the next image
        time.sleep(1)

# Replace with the actual camera ID from the NYC webcam API
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Example camera ID
display_and_track_cars(camera_id)

import cv2

# Check the location of Haar Cascade file
print(cv2.data.haarcascades)

# Load the Haar Cascade file
car_cascade = cv2.CascadeClassifier(cascade_path)

# Check if the cascade is loaded properly
if car_cascade.empty():
    print("Error loading Haar Cascade!")
else:
    print("Haar Cascade loaded successfully!")

import os

# Check if the file exists in the current directory
cascade_path = '/content/haarcascade_car.xml'
if os.path.exists(cascade_path):
    print("Haar Cascade file found!")
else:
    print("Haar Cascade file not found!")

import requests

# Manually download the Haar Cascade for car detection
cascade_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_car.xml'
cascade_path = '/content/haarcascade_car.xml'

# Download the file if it doesn't exist
if not os.path.exists(cascade_path):
    print(f"Downloading Haar Cascade from {cascade_url}...")
    response = requests.get(cascade_url)
    with open(cascade_path, 'wb') as file:
        file.write(response.content)
    print(f"Saved Haar Cascade to {cascade_path}")
else:
    print(f"Haar Cascade already exists at {cascade_path}")

# Check if the file content looks valid
cascade_path = '/content/haarcascade_car.xml'

# Read the file and print a few lines
with open(cascade_path, 'r') as file:
    content = file.readlines()

# Print the first 10 lines to check the contents
print("First 10 lines of the Haar Cascade XML file:")
for line in content[:10]:
    print(line)

import os
import requests

# Path to save the Haar Cascade
cascade_path = '/content/haarcascade_car.xml'

# Correct URL for downloading Haar Cascade for car detection
cascade_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_car.xml'

# Function to download the Haar Cascade if not present
def download_cascade():
    print(f"Downloading Haar Cascade from {cascade_url}...")
    response = requests.get(cascade_url)
    if response.status_code == 200:
        with open(cascade_path, 'wb') as file:
            file.write(response.content)
        print(f"Saved Haar Cascade to {cascade_path}")
    else:
        print(f"Failed to download Haar Cascade, status code: {response.status_code}")

# Check if the Haar Cascade file exists, if not, download it
if not os.path.exists(cascade_path):
    download_cascade()
else:
    print(f"Haar Cascade already exists at {cascade_path}")

# Load the Haar Cascade
import cv2
car_cascade = cv2.CascadeClassifier(cascade_path)

# Check if the cascade was loaded successfully
if car_cascade.empty():
    print("Error loading Haar Cascade!")
else:
    print("Haar Cascade loaded successfully!")

# Check the first few lines of the Haar Cascade file
with open(cascade_path, 'r') as file:
    lines = file.readlines()

# Print the first 10 lines
print("First 10 lines of the Haar Cascade file:")
for line in lines[:10]:
    print(line)

import requests

# URL for the Haar Cascade XML file for car detection
cascade_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_car.xml'
cascade_path = '/content/haarcascade_car.xml'

# Re-download the Haar Cascade file
response = requests.get(cascade_url)
if response.status_code == 200:
    with open(cascade_path, 'wb') as file:
        file.write(response.content)
    print("Downloaded Haar Cascade successfully!")
else:
    print("Failed to download Haar Cascade!")

# Check the contents of the newly downloaded file
with open(cascade_path, 'r') as file:
    lines = file.readlines()
    print("First 10 lines of the Haar Cascade file:")
    for line in lines[:10]:
        print(line)

import requests

# URL for the Haar Cascade XML file for car detection
cascade_url = 'https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_car.xml'
cascade_path = '/content/haarcascade_car.xml'

# Download the Haar Cascade file
response = requests.get(cascade_url)
if response.status_code == 200:
    with open(cascade_path, 'wb') as file:
        file.write(response.content)
    print("Downloaded Haar Cascade successfully!")
else:
    print(f"Failed to download Haar Cascade, status code: {response.status_code}")

!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_car.xml -O /content/haarcascade_car.xml

!wget https://github.com/souravdeyone/OpenCV-Reference/blob/master/Haarcascades/haarcascade_car.xml

import cv2
import os

# Path to the Haar Cascade file
cascade_path = '/content/haarcascade_car.xml'  # Adjust the path based on your upload location

# Load the Haar Cascade
car_cascade = cv2.CascadeClassifier(cascade_path)

# Check if the Haar Cascade is loaded correctly
if car_cascade.empty():
    print("Error loading Haar Cascade!")
else:
    print("Haar Cascade loaded successfully!")

import requests
import numpy as np
import cv2

# Example: Use webcam image URL (replace with your own webcam image URL)
base_url = 'https://webcams.nyctmc.org/api/cameras/b5a78bda-3ca9-4ad4-bd03-4cee70baba2d/image'

def fetch_and_process_image():
    # Fetch image from the webcam URL
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Loop to detect cars in the live webcam stream
while True:
    image = fetch_and_process_image()
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Detect cars using the Haar Cascade
    cars = car_cascade.detectMultiScale(gray, 1.1, 1)

    # Draw rectangles around the detected cars
    for (x, y, w, h) in cars:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

    # Display the image with detected cars
    cv2.imshow("Detected Cars", image)

    # Press 'q' to quit
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()

import cv2
import requests
import numpy as np

# Path to Haar Cascade
cascade_path = '/content/haarcascade_car.xml'  # Adjust if needed
car_cascade = cv2.CascadeClassifier(cascade_path)

# Check if cascade is loaded
if car_cascade.empty():
    print("Error loading Haar Cascade!")
else:
    print("Haar Cascade loaded successfully!")

# Fetch the image from the webcam
def fetch_and_process_image():
    base_url = 'https://webcams.nyctmc.org/api/cameras/b5a78bda-3ca9-4ad4-bd03-4cee70baba2d/image'
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Detect cars in the webcam image
def detect_cars_in_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    cars = car_cascade.detectMultiScale(gray, 1.1, 1)

    # Draw rectangles around detected cars
    for (x, y, w, h) in cars:
        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)

    return image

# Test the detection on a live webcam feed
while True:
    image = fetch_and_process_image()

    # Detect and annotate cars in the image
    image_with_cars = detect_cars_in_image(image)

    # Display the annotated image
    cv2.imshow("Detected Cars", image_with_cars)

    # Exit loop on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cv2.destroyAllWindows()

import os

# Check if the file exists
cascade_path = '/content/haarcascade_car.xml'
if not os.path.exists(cascade_path):
    print(f"Error: The file does not exist at {cascade_path}")
else:
    print(f"The file exists at {cascade_path}")

# Check the contents of the Haar Cascade file
with open('/content/haarcascade_car.xml', 'r') as file:
    print(file.read(1000))  # Print the first 1000 characters to verify it's a valid XML

# Use the built-in face detection Haar cascade
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Check if it loads
if face_cascade.empty():
    print("Error loading face Haar Cascade!")
else:
    print("Face Haar Cascade loaded successfully!")

!wget https://github.com/opencv/opencv/raw/master/data/haarcascades/haarcascade_car.xml -O /content/haarcascade_car.xml

!wget https://raw.githubusercontent.com/Guanghan/Car-Detection/master/cascade.xml -O /content/haarcascade_car.xml

# Download YOLOv3 configuration file, weights, and COCO class labels
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg -O /content/yolov3.cfg
!wget https://pjreddie.com/media/files/yolov3.weights -O /content/yolov3.weights
!wget https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names -O /content/coco.names

import cv2
import numpy as np
import requests

# Load YOLO
yolo_net = cv2.dnn.readNet("/content/yolov3.weights", "/content/yolov3.cfg")

# Get the output layer names
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]  # Adjust for indexing

# Load COCO class labels (these include vehicles, such as 'car', 'bus', etc.)
with open("/content/coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to fetch the webcam image from the NYC API
def fetch_and_process_image(camera_id):
    base_url = f'https://webcams.nyctmc.org/api/cameras/{camera_id}/image'
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Function to detect vehicles using YOLO
def detect_vehicles_yolo(image):
    height, width, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outs = yolo_net.forward(output_layers)

    # Process YOLO output and filter detected vehicles (car, bus, truck, etc.)
    class_ids = []
    confidences = []
    boxes = []
    vehicle_classes = [2, 3, 5, 7]  # 2: car, 3: motorcycle, 5: bus, 7: truck

    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if class_id in vehicle_classes and confidence > 0.5:  # Detect vehicles with confidence > 50%
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Apply non-maxima suppression to remove overlapping boxes
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    return class_ids, confidences, boxes, indices

# Function to display the detected vehicles
def display_detected_vehicles(image, class_ids, confidences, boxes, indices):
    for i in range(len(boxes)):
        if i in indices:
            x, y, w, h = boxes[i]
            label = str(classes[class_ids[i]])
            confidence = confidences[i]
            color = (0, 255, 0)  # Green color for vehicles

            # Draw bounding box
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)

            # Display label and confidence
            cv2.putText(image, f"{label}: {confidence:.2f}", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    return image

# Function to track and log congestion price for detected vehicles
def track_and_log_congestion_price(image):
    # Get detected vehicles and their bounding boxes
    class_ids, confidences, boxes, indices = detect_vehicles_yolo(image)

    # Count the vehicles and log the congestion price
    congestion_price_per_vehicle = 9  # $9 per vehicle
    vehicle_count = len(indices)

    total_congestion_price = vehicle_count * congestion_price_per_vehicle

    # Display congestion pricing info
    print(f"Number of vehicles detected: {vehicle_count}")
    print(f"Total congestion price: ${total_congestion_price}")

    # Display the image with detected vehicles
    image_with_vehicles = display_detected_vehicles(image, class_ids, confidences, boxes, indices)
    return image_with_vehicles

# Example usage: track and log congestion price from a specific webcam
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Replace with actual camera ID
image = fetch_and_process_image(camera_id)

# Process the image and track vehicles
image_with_vehicles = track_and_log_congestion_price(image)

# Show the image with detected vehicles and congestion price
cv2.imshow("Detected Vehicles with Congestion Price", image_with_vehicles)
cv2.waitKey(0)
cv2.destroyAllWindows()

from google.colab.patches import cv2_imshow

# Example usage: track and log congestion price from a specific webcam
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Replace with actual camera ID
image = fetch_and_process_image(camera_id)

# Process the image and track vehicles
image_with_vehicles = track_and_log_congestion_price(image)

# Show the image with detected vehicles and congestion price
cv2_imshow(image_with_vehicles)

import time
import cv2
import numpy as np
import requests
from google.colab.patches import cv2_imshow

# Load YOLO
yolo_net = cv2.dnn.readNet("/content/yolov3.weights", "/content/yolov3.cfg")
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]

# Load COCO class labels (these include vehicles, such as 'car', 'bus', etc.)
with open("/content/coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to fetch the webcam image from the NYC API
def fetch_and_process_image(camera_id):
    base_url = f'https://webcams.nyctmc.org/api/cameras/{camera_id}/image'
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Function to detect vehicles using YOLO
def detect_vehicles_yolo(image):
    height, width, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outs = yolo_net.forward(output_layers)

    # Process YOLO output and filter detected vehicles (car, bus, truck, etc.)
    class_ids = []
    confidences = []
    boxes = []
    vehicle_classes = [2, 3, 5, 7]  # 2: car, 3: motorcycle, 5: bus, 7: truck

    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if class_id in vehicle_classes and confidence > 0.5:  # Detect vehicles with confidence > 50%
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Apply non-maxima suppression to remove overlapping boxes
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    return class_ids, confidences, boxes, indices

# Function to display the detected vehicles
def display_detected_vehicles(image, class_ids, confidences, boxes, indices):
    for i in range(len(boxes)):
        if i in indices:
            x, y, w, h = boxes[i]
            label = str(classes[class_ids[i]])
            confidence = confidences[i]
            color = (0, 255, 0)  # Green color for vehicles

            # Draw bounding box
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)

            # Display label and confidence
            cv2.putText(image, f"{label}: {confidence:.2f}", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    return image

# Function to track and log congestion price for detected vehicles
def track_and_log_congestion_price(image):
    # Get detected vehicles and their bounding boxes
    class_ids, confidences, boxes, indices = detect_vehicles_yolo(image)

    # Count the vehicles and log the congestion price
    congestion_price_per_vehicle = 9  # $9 per vehicle
    vehicle_count = len(indices)

    total_congestion_price = vehicle_count * congestion_price_per_vehicle

    # Display congestion pricing info
    print(f"Number of vehicles detected: {vehicle_count}")
    print(f"Total congestion price: ${total_congestion_price}")

    # Display the image with detected vehicles
    image_with_vehicles = display_detected_vehicles(image, class_ids, confidences, boxes, indices)
    return image_with_vehicles, total_congestion_price

# Function to fetch and process the webcam images periodically
def update_and_tally_congestion(camera_id):
    total_congestion_price = 0

    while True:
        image = fetch_and_process_image(camera_id)

        # Process the image and track vehicles
        image_with_vehicles, congestion_price = track_and_log_congestion_price(image)

        # Add the congestion price from the current frame
        total_congestion_price += congestion_price

        # Display the image with detected vehicles and congestion price
        cv2.putText(image_with_vehicles, f"Total Congestion Price: ${total_congestion_price}",
                    (10, image_with_vehicles.shape[0] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        # Show the updated image with the congestion tally
        cv2_imshow(image_with_vehicles)

        # Wait for a second before fetching the next image
        time.sleep(1)

# Example usage: track and log congestion price from a specific webcam
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Replace with actual camera ID
update_and_tally_congestion(camera_id)

import time
import cv2
import numpy as np
import requests
from google.colab.patches import cv2_imshow

# Load YOLO
yolo_net = cv2.dnn.readNet("/content/yolov3.weights", "/content/yolov3.cfg")
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]

# Load COCO class labels (these include vehicles, such as 'car', 'bus', etc.)
with open("/content/coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to fetch the webcam image from the NYC API
def fetch_and_process_image(camera_id):
    base_url = f'https://webcams.nyctmc.org/api/cameras/{camera_id}/image'
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Function to detect vehicles using YOLO
def detect_vehicles_yolo(image):
    height, width, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outs = yolo_net.forward(output_layers)

    # Process YOLO output and filter detected vehicles (car, bus, truck, etc.)
    class_ids = []
    confidences = []
    boxes = []
    vehicle_classes = [2, 3, 5, 7]  # 2: car, 3: motorcycle, 5: bus, 7: truck

    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if class_id in vehicle_classes and confidence > 0.5:  # Detect vehicles with confidence > 50%
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Apply non-maxima suppression to remove overlapping boxes
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    return class_ids, confidences, boxes, indices

# Function to display the detected vehicles (only green boxes, no text)
def display_detected_vehicles(image, class_ids, confidences, boxes, indices):
    for i in range(len(boxes)):
        if i in indices:
            x, y, w, h = boxes[i]
            # Use green color for bounding boxes
            color = (0, 255, 0)

            # Draw bounding box (no label, just green boxes)
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)

    return image

# Function to track and log congestion price for detected vehicles
def track_and_log_congestion_price(image):
    # Get detected vehicles and their bounding boxes
    class_ids, confidences, boxes, indices = detect_vehicles_yolo(image)

    # Count the vehicles and log the congestion price
    congestion_price_per_vehicle = 9  # $9 per vehicle
    vehicle_count = len(indices)

    total_congestion_price = vehicle_count * congestion_price_per_vehicle

    # Display congestion pricing info in the console
    print(f"Number of vehicles detected: {vehicle_count}")
    print(f"Total congestion price: ${total_congestion_price}")

    # Display the image with detected vehicles (green bounding boxes only)
    image_with_vehicles = display_detected_vehicles(image, class_ids, confidences, boxes, indices)
    return image_with_vehicles, total_congestion_price

# Function to fetch and process the webcam images periodically
def update_and_tally_congestion(camera_id):
    total_congestion_price = 0

    while True:
        image = fetch_and_process_image(camera_id)

        # Process the image and track vehicles
        image_with_vehicles, congestion_price = track_and_log_congestion_price(image)

        # Add the congestion price from the current frame
        total_congestion_price += congestion_price

        # Show the updated image with the detected vehicles (green bounding boxes only)
        cv2_imshow(image_with_vehicles)

        # Wait for a second before fetching the next image
        time.sleep(1)

# Example usage: track and log congestion price from a specific webcam
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Replace with actual camera ID
update_and_tally_congestion(camera_id)

import time
import cv2
import numpy as np
import requests
from google.colab.patches import cv2_imshow

# Load YOLO
yolo_net = cv2.dnn.readNet("/content/yolov3.weights", "/content/yolov3.cfg")
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]

# Load COCO class labels (these include vehicles, such as 'car', 'bus', etc.)
with open("/content/coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to fetch the webcam image from the NYC API
def fetch_and_process_image(camera_id):
    base_url = f'https://webcams.nyctmc.org/api/cameras/{camera_id}/image'
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Function to detect vehicles using YOLO
def detect_vehicles_yolo(image):
    height, width, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outs = yolo_net.forward(output_layers)

    # Process YOLO output and filter detected vehicles (car, bus, truck, etc.)
    class_ids = []
    confidences = []
    boxes = []
    vehicle_classes = [2, 3, 5, 7]  # 2: car, 3: motorcycle, 5: bus, 7: truck

    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if class_id in vehicle_classes and confidence > 0.5:  # Detect vehicles with confidence > 50%
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Apply non-maxima suppression to remove overlapping boxes
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    return class_ids, confidences, boxes, indices

# Function to display the detected vehicles (only green boxes, no text)
def display_detected_vehicles(image, class_ids, confidences, boxes, indices):
    for i in range(len(boxes)):
        if i in indices:
            x, y, w, h = boxes[i]
            # Use green color for bounding boxes
            color = (0, 255, 0)

            # Draw bounding box (no label, just green boxes)
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)

    return image

# Function to add total congestion price text to the image
def add_congestion_price_text(image, total_congestion_price):
    text = f"Total Congestion Price: ${total_congestion_price}"
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.7
    font_thickness = 2
    color = (255, 255, 255)  # Green color for the text

    # Get the text size
    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)

    # Calculate the position to center the text at the bottom of the image
    height, width, _ = image.shape
    x_position = (width - text_width) // 2  # Center the text horizontally
    y_position = height - 20  # Position text just above the bottom

    # Add the text to the image
    cv2.putText(image, text, (x_position, y_position), font, font_scale, color, font_thickness)

    return image

# Function to track and log congestion price for detected vehicles
def track_and_log_congestion_price(image):
    # Get detected vehicles and their bounding boxes
    class_ids, confidences, boxes, indices = detect_vehicles_yolo(image)

    # Count the vehicles and log the congestion price
    congestion_price_per_vehicle = 9  # $9 per vehicle
    vehicle_count = len(indices)

    total_congestion_price = vehicle_count * congestion_price_per_vehicle

    # Display the image with detected vehicles (green bounding boxes only)
    image_with_vehicles = display_detected_vehicles(image, class_ids, confidences, boxes, indices)

    # Add the congestion price text to the image
    image_with_congestion_text = add_congestion_price_text(image_with_vehicles, total_congestion_price)

    return image_with_congestion_text, total_congestion_price

# Function to fetch and process the webcam images periodically
def update_and_tally_congestion(camera_id):
    total_congestion_price = 0

    while True:
        image = fetch_and_process_image(camera_id)

        # Process the image and track vehicles
        image_with_vehicles, congestion_price = track_and_log_congestion_price(image)

        # Add the congestion price from the current frame
        total_congestion_price += congestion_price

        # Show the updated image with the detected vehicles and congestion price
        cv2_imshow(image_with_vehicles)

        # Wait for a second before fetching the next image
        time.sleep(1)

# Example usage: track and log congestion price from a specific webcam
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Replace with actual camera ID
update_and_tally_congestion(camera_id)

import time
import cv2
import numpy as np
import requests
from google.colab.patches import cv2_imshow

# Load YOLO
yolo_net = cv2.dnn.readNet("/content/yolov3.weights", "/content/yolov3.cfg")
layer_names = yolo_net.getLayerNames()
output_layers = [layer_names[i - 1] for i in yolo_net.getUnconnectedOutLayers()]

# Load COCO class labels (these include vehicles, such as 'car', 'bus', etc.)
with open("/content/coco.names", "r") as f:
    classes = [line.strip() for line in f.readlines()]

# Function to fetch the webcam image from the NYC API
def fetch_and_process_image(camera_id):
    base_url = f'https://webcams.nyctmc.org/api/cameras/{camera_id}/image'
    response = requests.get(base_url)
    img_array = np.array(bytearray(response.content), dtype=np.uint8)
    image = cv2.imdecode(img_array, -1)
    return image

# Function to detect vehicles using YOLO
def detect_vehicles_yolo(image):
    height, width, channels = image.shape
    blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    yolo_net.setInput(blob)
    outs = yolo_net.forward(output_layers)

    # Process YOLO output and filter detected vehicles (car, bus, truck, etc.)
    class_ids = []
    confidences = []
    boxes = []
    vehicle_classes = [2, 3, 5, 7]  # 2: car, 3: motorcycle, 5: bus, 7: truck

    for out in outs:
        for detection in out:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if class_id in vehicle_classes and confidence > 0.5:  # Detect vehicles with confidence > 50%
                center_x = int(detection[0] * width)
                center_y = int(detection[1] * height)
                w = int(detection[2] * width)
                h = int(detection[3] * height)
                x = int(center_x - w / 2)
                y = int(center_y - h / 2)

                boxes.append([x, y, w, h])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    # Apply non-maxima suppression to remove overlapping boxes
    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)

    return class_ids, confidences, boxes, indices

# Function to display the detected vehicles (only green boxes, no text)
def display_detected_vehicles(image, class_ids, confidences, boxes, indices):
    for i in range(len(boxes)):
        if i in indices:
            x, y, w, h = boxes[i]
            # Use green color for bounding boxes
            color = (0, 255, 0)

            # Draw bounding box (no label, just green boxes)
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)

    return image

# Function to add total congestion price text to the image
def add_congestion_price_text(image, total_congestion_price, total_cars):
    text = f"Cars Seen: {total_cars} | Total Congestion Price: ${total_congestion_price}"
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 0.7
    font_thickness = 2
    color = (255, 255, 255)  # Green color for the text

    # Get the text size
    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, font_thickness)

    # Calculate the position to center the text at the bottom of the image
    height, width, _ = image.shape
    x_position = (width - text_width) // 2  # Center the text horizontally
    y_position = height - 20  # Position text just above the bottom

    # Add the text to the image
    cv2.putText(image, text, (x_position, y_position), font, font_scale, color, font_thickness)

    return image

# Function to track and log congestion price for detected vehicles
def track_and_log_congestion_price(image):
    # Get detected vehicles and their bounding boxes
    class_ids, confidences, boxes, indices = detect_vehicles_yolo(image)

    # Count the vehicles and log the congestion price
    congestion_price_per_vehicle = 9.00  # $9 per vehicle
    vehicle_count = len(indices)

    total_congestion_price = vehicle_count * congestion_price_per_vehicle

    # Display the image with detected vehicles (green bounding boxes only)
    image_with_vehicles = display_detected_vehicles(image, class_ids, confidences, boxes, indices)

    # Add the congestion price text to the image
    image_with_congestion_text = add_congestion_price_text(image_with_vehicles, total_congestion_price, vehicle_count)

    return image_with_congestion_text, vehicle_count, total_congestion_price

# Function to fetch and process the webcam images periodically
def update_and_tally_congestion(camera_id):
    total_congestion_price = 0
    total_cars_seen = 0

    while True:
        image = fetch_and_process_image(camera_id)

        # Process the image and track vehicles
        image_with_vehicles, vehicle_count, congestion_price = track_and_log_congestion_price(image)

        # Add the car count and congestion price from the current frame
        total_cars_seen += vehicle_count
        total_congestion_price += congestion_price

        # Show the updated image with the detected vehicles and congestion price
        cv2_imshow(image_with_vehicles)

        # Print the updated information in the console (optional)
        print(f"Total Congestion Price: ${total_congestion_price}")

        # Wait for a second before fetching the next image
        time.sleep(1)

# Example usage: track and log congestion price from a specific webcam
camera_id = "b5a78bda-3ca9-4ad4-bd03-4cee70baba2d"  # Replace with actual camera ID
update_and_tally_congestion(camera_id)